---
issueTitle: Disgusted, but not surprised
intro: Police violence for fossil future, stochastic parrots doing cybercrime, TikTok’s secret, Tesla’s magic, and why peer review failed.
dates:
  start: '2022-12-14'
  publish: '2023-01-15'
tags:
  - 'cat:ai'
  - 'cat:surveillance-state'
  - 'cat:surveillance-capitalism'
  - 'cat:social-media'
  - 'cat:technology'
  - 'cat:climate'
  - 'cat:cycling'
  - 'cat:infosec'
  - 'cat:science'
---

Welcome to Around the Web.

For a brief moment, it seemed like Greta Thunberg managed to slam dunk Andrew Tate into jail. It seemed like the perfect Christmas miracle. [But wasn't true after all](https://www.washingtonpost.com/world/2022/12/30/andrew-tate-detained-romania-brothers-crime/). Still, Tate faces prosecution in Romania after fleeing to Romania because he thought he won’t be prosecuted there.

[Never forget](https://mastodon.se/@osiris/109597375879403687) and welcome 2023. Behave yours… ah, well, too late.

## Lützerath

On Wednesday, Germany decided to fuck around and find out. The fucking around is the goal to limit global warming to 1,5 degree Celsius. Cops from almost all states converged on the squatted village Lützerath in North-Rhine Westphalia.

The village lies adjacent to [Garzweiler](https://de.wikipedia.org/wiki/Tagebau_Garzweiler), a gargantuan, dystopian coal mine. Enough coal to emit around 280 million tonnes of CO2 when burned.

And that’s the problem. By giving the energy company RWE permission to mine and burn the coal, [Germany will certainly not be able to meet the 1.5 degree target](https://www.diw.de/documents/publikationen/73/diw_01.c.819609.de/diwkompakt_2021-169.pdf). As if that wasn’t already highly unlikely.

All of this could have been prevented, it’s [not even like Germany needs the coal for anything other than RWE’s profits](https://background.tagesspiegel.de/energie-klima/luetzerath-muss-nicht-zerstoert-werden). But here we are.

The Greens from the local to federal level transformed into RWE’s PR department, parroting claims that the coal is indeed needed. A «deal» to speed up the coal phase-out, which at the same time allows burning even more coal in the shorter timeframe serves as the fig leave. It took the Greens – almost to the day – 32 years to successfully end their march through the institutions: By becoming the institution and betraying everything they stood for.

Luisa Neubauer und Pauline Brünger wrote [a commentary for the German newspaper taz](https://taz.de/Fridays-for-Future-ueber-Luetzerath/!5903446/), succinctly describing the dire situation we are in. [The consequences of which will be felt worldwide](https://www.medico.de/was-ist-eigentlich-legitim-18942).

!["A spookily lit picture of a group of riot cops, helms, shields and all, standing in front of a gigantic bucket excavator."](_src/assets/img/posts/orcs-of-luetzerath.jpg 'German climate policy (Symbolic image), [photo by Carla Hinrichs](https://twitter.com/carla_hinrichs_/status/1612741256915853312/photo/1)')

On Wednesday, January 11th, police moved in and started the eviction.

On Saturday, January 14th, tens of thousands of protesters travelled to Lützerath to support those activists remaining in the village.

The police [promised](https://youtu.be/qjqjd-xJ2tE?t=109) «unpleasant images if protesters try to break through to Lützerath».

The day ended with [several serious injuries](https://archive.ph/AdD0E), one protester was hospitalised with life-threatening injuries. In one case, [police officers continued to beat an injured person despite ongoing treatment by the paramedics](https://twitter.com/LuetziBleibt/status/1614364552178634752). Iza Hoffmann, a paramedic, described the actions of the police as «[fear and terror](https://twitter.com/izahofmann_/status/1614363893937340417)». Journalists say they were [assaulted by the police and obstructed in their reporting](https://netzpolitik.org/2023/klimaproteste-schikanen-und-uebergriffe-gegen-presse-in-luetzeraths).

One thing is abundantly clear: Every cop showing up to work – work being hitting the heads of protesters – does so by choice. [They choose violence](https://twitter.com/Dzienus/status/1614265103758643202). The only good cop is a cop that quits their job.

At the time of writing this newsletter, according to the police, the eviction has finished, with all activists but two hiding in a tunnel removed from the village. [Ende Gelände mobilises for a return to Lützerath on January, 17th](https://www.ende-gelaende.org/news/luetzerath-unraeumbar/).

And that’s the situation we’ll have to deal with. Cops won’t quit their job. Politicians will use climate change only to garner some votes in the next election. RWE will excavate the coal. Germany will miss its climate targets.

Activists will continue to give them hell. There’s no other way out.

To end on a lighter note, cops stuck in mud and trolled by a protester in a monk’s costume is, simply, the best. Thank you, monk.

[https://twitter.com/UniversUltra/status/1614433332611235840](https://twitter.com/UniversUltra/status/1614433332611235840)

## Storm a Parliament Month

While Jair Bolsonaro hides away in Florida, his supporters took to the streets and stormed Brasil’s parliament. Which makes January the official Storm a Parliament Month. I wonder which one is next.

It’s easy to categorise these events as just another version of January, 6th. But that’s too simple. For one, storming the parliament [has been attempted in Germany before](https://www.rnd.de/politik/sorgen-wurden-wahr-corona-demo-mit-sturm-auf-den-reichstag-QF6VWMMHHJA7ZPXRNG4KORCKWA.html). Didn’t happen in January, though, and was stopped by a total of two police officers.

And, as Ryan Broderick argues in Garbage Day, the [Brazilian version isn’t a reenactment, it’s an escalation](https://www.garbageday.email/p/on-the-cutting-edge-of-insurrectionist).

Also, unlike after the storm on the capitol, Brazilian police was able to detain 1,000 would be insurrectionists.

## This ain’t intelligence

Maggie Appleton wrote an amazing [essay on proving you're a human on a web flooded with generative AI content](https://maggieappleton.com/ai-dark-forest).

Issue number 200 of Last Week in AI [provides a look back at 2022](https://lastweekin.ai/p/200). The year was rich with break-throughs (DALL-E 2 was released only in April) and of course a lot of AI hype theatre. Luckily, Emily M. Bender and Alex Hanna [made a show out of it](https://videos.trom.tf/w/p/4gykGcMrmHHs7bG2Y6qK9W) and pushed back on some of the more common (and outlandish) claims.

Meanwhile, we have ChatGPT running around the hype theatre.

Seemingly everybody uses it for everything, but in reality, it’s incredibly hard to know whether the information spouted by the model is true or not. Eva Wolfangel took a [closer look at this in German science magazine Spektrum](https://www.spektrum.de/news/maschinelles-lernen-chatgpt-wird-immer-plappern/2090727).

> Wenn ChatGPT also noch so intelligent wirkt, machen wir uns klar: Das ist eine Täuschung. Das System nutzt unsere kognitive Schwäche aus, die Sprachgewandtheit mit Intelligenz in Verbindung bringt.

Keep in mind that Microsoft has exclusive usage rights for everything OpenAI publishes. [Bing will implement ChatGPT](https://www.theguardian.com/technology/2023/jan/05/microsoft-chatgpt-bing-search-engine). [Google declared a Code Red over ChatGPT’s popularity](https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html), acknowledging publicly the danger such models can persist to the business models of IT companies.

The implementation of Large Language Models as each interfaces face problems, though. First, as Emily Bender and Chirag Shah argue in \<cite\>[Situating Search](https://dl.acm.org/doi/10.1145/3498366.3505816)\</cite\>, LLMs can not present information in a way that allows the searcher to know where it comes from, and hence if the source is reliable or not – or if it exists at all.

The other problem, how do you make money out of it? A search with ChatGPT is estimated to cost a cent. This quickly adds up if you take Bing’s size into account.

Episode 221 of This Machine Kills [discusses the political economy behind these models](https://www.patreon.com/posts/premium-221-from-76715102). In the end, all models are a way to make money, and 2023 will be the year when we see the ways to make money.

[GPTZero is a tool designed to detect the output of ChatGPT](https://www.npr.org/2023/01/09/1147549845/gptzero-ai-chatgpt-edward-tian-plagiarism) based on linguistic properties. [Hugging Face developed a similar tool for GPT-2](https://openai-openai-detector.hf.space/), which seems to work for ChatGPT, too.

This kind of tools [might be a future revenue stream for OpenAI and their ilk](https://ideophone.org/monetizing-uninformation-a-prediction/).

> But the second reason is to enable a new form of monetization. Flood the zone with bullshit (or facilitate others doing so), then offer paid services to detect said bullshit. (I use bullshit as a technical term for text produced without commitment to truth values; see Frankfurt 2009.) It’s guaranteed to work because as I wrote, the market forces are in place and they will be relentless.

[Cybercriminals start using ChatGPT](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/). Because why wouldn't they.

Want to use ChatGPT, but are an open-source type of person? [There’s now an open-source alternative to ChatGPT, but good luck running it](https://techcrunch.com/2022/12/30/theres-now-an-open-source-alternative-to-chatgpt-but-good-luck-running-it/).

David Holz, founder of Midjourney, admitted that [there’s no way to train a model searching proper consent beforehand](https://petapixel.com/2022/12/21/midjourny-founder-admits-to-using-a-hundred-million-images-without-consent/).

The Washington Post created a [visual explainer of the process behind generative AI models](https://www.washingtonpost.com/technology/interactive/2022/ai-image-generator/) such as DALL-E or Stable Diffusion.

Following GitHub, Stability AI, makers of Stable Diffusion, is now [sued over their use of copyrighted content](https://stablediffusionlitigation.com/). The site skips on the legalese, while doing a pretty solid job explaining the diffusion process and why they think collage tools such as Stable Diffusion.

German public broadcaster, ZDF, [published information, including model cards, of the algorithms used to fine-tune personalisation in their digital offering](https://hrdm-reco-modelcards-prod.appcluster.zdf.de/). Well done.

[China now enforces its AI legislation](https://www.wsj.com/amp/articles/china-a-pioneer-in-regulating-algorithms-turns-its-focus-to-deepfakes-11673149283), meaning the output of generative AI has to be clearly labeled, and is not allowed to be used to produce deep fakes.

[Microsoft announced VALL-E](https://mpost.io/vall-e-microsofts-new-zero-shot-text-to-speech-model-can-duplicate-everyones-voice-in-three-seconds/), a speech synthesiser [which only needs three seconds of input to duplicate a person’s voice](https://arstechnica.com/information-technology/2023/01/microsofts-new-ai-can-simulate-anyones-voice-with-3-seconds-of-audio/). I can’t for the life of me imagine what could go wrong.

The fight over the EU’s AI Act continues, [Germany favours more broad exception for facial recognition technology](https://digit.site36.net/2023/01/10/ai-act-german-government-in-favour-of-facial-recognition-but-against-lie-detectors/).

## Social Mediargh

I kind of lost interest in Twitter, but thanks to my friends at [Twitter Is Going Great](https://twitterisgoinggreat.com/) I can rest assured that it’s going terrific, with CSAM material [still prevalent on the platform](https://www.nbcnews.com/tech/tech-news/musk-twitter-elon-child-abuse-material-rcna63621) and some [3rd party apps cut off from their API without any explanation](https://9to5mac.com/2023/01/13/tweetbot-twitter-apps-still-broken-elon-musk-api/). So yeah, perfect. Here’s an [ interview with Markus Beckedahl explaining the misery from a journalistic perspective](https://www.youtube.com/watch?app=desktop&v=OcUfXLza9hI). And here [Some More News on Musk and free speech](https://www.youtube.com/watch?v=RlL4xvn6xWE).

Musk’s takeover [drove more than a million people to Mastodon – but many aren’t sticking around](https://www.theguardian.com/news/datablog/2023/jan/08/elon-musk-drove-more-than-a-million-people-to-mastodon-but-many-arent-sticking-around). Mastodon’s user numbers still are higher than before the takeover.

TikTok has been accused of [pushing content promoting eating disorders and self-harm in the feeds of teenagers](https://counterhate.com/research/deadly-by-design/).

TikTok’s success has often been attributed (including by me) to its algorithm. The truth might be slightly different. As Arvind Narayanan argues, [the true advantage might be the way TikTok is designed around the algorithm](https://knightcolumbia.org/blog/tiktoks-secret-sauce).

> TikTok’s recommender system is not its secret: rather, it’s the design, which, of course, isn’t secret at all. More generally, in AI applications, the sophistication of the algorithm is rarely the limiting factor. The quality of the design, the data, and the people that make up the system all tend to matter more.

This might explain the trouble every other tech company has in replicating TikTok’s success «because they were originally designed for a very different experience, and they are locked into it due to their users’ and creators’ preferences».

[Facebook, meanwhile was fined 390 million Euro](https://dataprotection.ie/en/news-media/data-protection-commission-announces-conclusion-two-inquiries-meta-ireland) and needs to revamp their recommendation algorithms within the next three months.

## What are you looking at?

A mother tries to go to a Christmas show with her daughter and her group of Girl Scouts. While entering the vicinity, security guards approached her and tell her she has to leave the building because she has the wrong job. Sounds far-fetched? Yes. And that’s [precisely the reason it happened](https://www.nbcnewyork.com/investigations/face-recognition-tech-gets-girl-scout-mom-booted-from-rockettes-show-due-to-her-employer/4004677/). The mother is employed by a law-firm currently suing a subsidiary of Madison Square Garden. The entertainment behemoth [subsequently scraped all employees photos from the law firm’s website](https://www.nytimes.com/2022/12/22/nyregion/madison-square-garden-facial-recognition.html) and fed them into the facial recognition system used to screen every guest at their venues. [They say they do nothing wrong](https://arstechnica.com/tech-policy/2022/12/facial-recognition-flags-girl-scout-mom-as-security-risk-at-rockettes-show/), which is quite a take.

PimEyes might [face a fine coming out of the German hinterland](https://netzpolitik.org/2022/bussgeldverfahren-aus-dem-laendle-pimeyes-droht-eine-millionenstrafe/). As always, enforcement is difficult, which is why I don’t hold my breath. Still, it’s good to see that regulators and data protection offices have PimEyes in their sight.

[German police use human «super recognisers»](https://www.nd-aktuell.de/artikel/1169812.gesichtserkennung-superwiedererkenner-bei-der-polizei.html) to identify persons suspected of doing crimes.

What’s your Roomba looking at? [You](https://www.technologyreview.com/2022/12/19/1065306/roomba-irobot-robot-vacuums-artificial-intelligence-training-data-privacy/). And because data wouldn’t be the same without a leak, the Internet can now look at you, too.

[Google is implementing an appeal process](https://www.nytimes.com/2022/12/30/technology/google-appeals-change.html?referringSource=articleShare&smid=nytcore-ios-share) for users whose accounts get locked if automated systems suspect the hosting of child sexual abuse material (CSAM). Last year, [cases have been publicised where Google accounts of parents have been locked](https://www.nytimes.com/2022/08/21/technology/google-surveillance-toddler-photo.html) because they uploaded photos of their children to send to doctors.

Palantir has sold their services to Ukraine’s armed forces, which reportedly gives them the edge over the Russian army. The Washington Post [was able to report on the use](https://www.washingtonpost.com/opinions/2022/12/19/palantir-algorithm-data-ukraine-war/).

The other side of collecting data in war zones has been [demonstrated by hackers from the Chaos Computer Club](https://www.nytimes.com/2022/12/27/technology/for-sale-on-ebay-a-military-database-of-fingerprints-and-iris-scans.html). They bought old US Army equipment on eBay and upon analysing it found that it [still contained biometric data collected in Afghanistan](https://netzpolitik.org/2022/auf-ebay-gekauft-hacker-finden-iris-scans-und-fotos-auf-gebrauchten-militaer-geraeten/).

## EOL of humanity

The Lancet [stepped up its warning about the public health emergency constituted by the climate crisis](<https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(22)02353-4/fulltext>):

> For these reasons the 2009 Lancet Commission on managing the health effects of climate change 3 described climate change as the “greatest global health threat of the 21st century”. However, it was wrong, both qualitatively and temporally. The threat is now to our very survival and to that of the ecosystem upon which we depend. Grave impacts of climate change are already with us and could worsen catastrophically within decades. A UN Environment Programme report states there is “no credible pathway to 1·5°C in place” today.

[Biodiversity is on a constant decline](https://www.reuters.com/graphics/GLOBAL-ENVIRONMENT/EXTINCT/lbvgggdgevq/), with conservation efforts lacking. Forty percent of insect species [are threatened by extinction](https://www.openmindmag.org/articles/saving-the-tiny-empires), thereby endangering the future of whole ecosystems.

> The potential dangers of widespread insect loss are alarming. And yet, while money, effort, and attention have been poured into saving the celebrated beasts of our time—the orangutans, the rhinos, the elephants—our attempts to arrest the loss of insects have barely begun. Many people also don’t yet realize how far the problem goes beyond honeybees. What’s required isn’t an army of urban beekeepers, but rather a fundamental rethink of our relationship with nature.

So, snafu. But at least there’s [a vaccine protecting honeybees from sickness](https://www.nytimes.com/2023/01/07/science/honeybee-vaccine.html?searchResultPosition=1). I dearly hope there are no anti-vax bees.

The UCI road cycling season kicked off in Australia. Cycling has a long and complicated history with complicated sponsors. Recently more and [more nation states buy their way into World Tour teams](https://www.peterlang.com/document/1069090). The Tour Down Under meanwhile is sponsored by Santos. Santos is Australia’s largest energy company. Burning coal and cycling don’t add up, really. But thanks to the power of greenwashing, why not. Extinction Rebellion demands to drop Santos’ sponsorship and started protests against the tour. Before the tour started, two members of the group [glued themselves to bikes in front of Santos’ headquarter](https://www.abc.net.au/news/2023-01-12/protest-against-santos-sponsoring-tour-down-under/101850098). The first day of the women’s race saw a [small protest at the site of the race](https://road.cc/content/news/naked-pensioners-arrested-tour-down-under-protest-298635).

## Information Insecurity

Over the holidays, LastPass was forced to admit that a previously disclosed breach was far worse than disclosed. They put a PR statement full of half-truths and attempts to [shift blame to their users](https://palant.info/2022/12/26/whats-in-a-pr-statement-lastpass-breach-explained/).

Shortly after, Slack announced that someone [accessed their internal GitHub repositories and stole source code](https://www.bleepingcomputer.com/news/security/slacks-private-github-code-repositories-stolen-over-holidays/). In an interesting use of technology, a `noindex` meta tag ended up on Slack’s blog page announcing the incident. Who knows why they don’t want search engines to index this post.

Hold Security published a [throve of data on Solaris](https://holdsecurity.com/news/2023/01/solaris-russian-drug-platform-exposed/), a Russian drug market. Including their Ansible scripts.

## Loose ends in a list of links

[Google is stuck with Gmail](https://www.theregister.com/2022/12/26/opinion_column_alexa/) and that might be a problem.

> Advertising within Gmail is very low key and easy to avoid altogether, and Google is very clear that it doesn’t monetize your email content: “We do not scan or read your Gmail messages to show you ads.“ Google has played fast and loose about how it uses data, but if it cheated here it would be beyond catastrophic.

[Tesla announced that their Cybertruck can «pull near-infinite mass»](https://nitter.net/melhuman/status/1610707061561765888) while towing 14,000 pounds (ca. 6,350 kg). Does anyone at Tesla know the meaning of words? I do know the meaning of the following words and, yes, please: [Tesla’s Brand Is Tanking, Survey Finds](https://www.forbes.com/sites/alanohnsman/2023/01/12/teslas-brand-is-tanking-survey-finds/).

[Trump’s Spiritual Adviser Paula White Accused of Breaking Into the Bank Account of Rock Band Journey](https://www.politicalflare.com/2023/01/trumps-spiritual-adviser-paula-white-accused-of-breaking-into-the-bank-account-of-rock-band-journey/). What a sentence.

Bye bye peer review? [Science’s biggest experiment has failed](https://experimentalhistory.substack.com/p/the-rise-and-fall-of-peer-review), and it’s past time to replace it with something else. What this else is? We have to find out.

A new book takes a closer look at the [archives and artefacts of LGTBQ+ cultural production](https://thebaffler.com/latest/past-in-present-lukenbill).

I haven’t finished my Mastodon embed plugin yet, so I’ll close this issue with [Martha Stewart’s eggnog recipe](https://www.marthastewart.com/355404/marthas-classic-eggnog).

---

That’s it for this issue. Stay sane, hug your friends, and don’t forget to mud the police.
